# DistillGPT4V

## Brief

DistillGPT4V is a Large Vision-Language Model(LVLM) just like LLaVA and InstructBLIP. It is capable of chatting with a single image as context. To distinguish itself from others, its examples with images are generated by GPT4V. It does NOT not use any academic or text-only GPT4 dataset. It should have the best performance for general purpose usage(not for benchmarking).

Its architecture is *indentical* to LLaVA-v1.5 but with better training data for image-caption alignment stage(Stage 1) and instruction fine-tuning stage(Stage 2).

After several months of researching on the hallucination of LVLMs, my efforts are doomed due to the release of GPT4V and its API. After tuning a simple model with finer data from GPT4V, the hallucinations are just gone, needless for any tricky methods. This model serves as a goodbye letter and a reminder to contemporary researchers that data quality really, really matters.

## Usage

The architure is identical to LLaVA-v1.5, so the {train, eval, demo, serve} are all the same as LLaVA-v1.5. See

[https://github.com/haotian-liu/LLaVA](https://github.com/haotian-liu/LLaVA)

Then specifying the models in the following model zoo.

## Model Zoo

| Name                                    | Stage | Checkpoint | LLM             | Vision Encoder | Projection | Pretrain  Data Amount | Finetune Data Amount             | Pretrain Data                                | Finetune Data                                                |
| --------------------------------------- | ----- | ---------- | --------------- | -------------- | ---------- | --------------------- | -------------------------------- | -------------------------------------------- | ------------------------------------------------------------ |
| DistillGPT4V-13B_vit-l14-336px          | 1,2   | training   | Vicuna-13B-v1.5 | CLIP-L-336px   | MLP-2x     | 1,166,048             | 359,787=<br />96388+222711+40688 | share-captioner_coco_lcs_sam_1246k_1107.json | sharegpt4v_instruct_gpt4-vision_cap100k.json(filtered ill examples)<br /> lvis_instruct4v_220k.json<br />llava_v1_5_mix665k.json(only text-only examples) |
| DistillGPT4V-13B_vit-l14-336px_Pretrain | 1     | training   | Vicuna-13B-v1.5 | CLIP-L-336px   | MLP-2x     | 1,166,048             | /                                | share-captioner_coco_lcs_sam_1246k_1107.json | /                                                            |
| DistillGPT4V-7B_vit-l14-336px           | 1,2   | training   | Vicuna-7B-v1.5  | CLIP-L-336px   | MLP-2x     | 1,166,048             | 359,787=<br />96388+222711+40688 | share-captioner_coco_lcs_sam_1246k_1107.json | sharegpt4v_instruct_gpt4-vision_cap100k.json(filtered ill examples)<br /> lvis_instruct4v_220k.json<br />llava_v1_5_mix665k.json(only text-only examples) |
| DistillGPT4V-7B_vit-l14-336px           | 1     | training   | Vicuna-7B-v1.5  | CLIP-L-336px   | MLP-2x     | 1,166,048             | /                                | share-captioner_coco_lcs_sam_1246k_1107.json | /                                                            |

## Training

Identical to LLaVA-v1.5.

### Stage 1: image-caption alignment

In this stage, only `mlp2x_gelu`, the projector, is trained. After training, it could do captioning in LLaVA's `plain` template (i.e. no chat template).

Dataset used:
- https://huggingface.co/datasets/Lin-Chen/ShareGPT4V, share-captioner_coco_lcs_sam_1246k_1107.json
    - It is NOT directly from GPT4V. It is a collection of caption data generated by Share-Captioner, which is a captioner trained on GPT4V captioning data. You can find more information in the huggingface page.
    - NOTE: we removed 80853 ill examples from it which contains 'sa_', see examples at #Ill examples of ShareGPT4V.
    - Contains images from
        - coco train2017
        - llava pretrain
        - sam pretrain dataset 000000-000051


### Stage 2: instruction fine-tuning

In this stage, the projector and the LLM are trained.

Dataset used:
- https://huggingface.co/datasets/Lin-Chen/ShareGPT4V, sharegpt4v_instruct_gpt4-vision_cap100k.json
    - Pure golden captioning instructions by prompting GPT4V.
    - NOTE: we removed 5637 ill examples from it which contains 'sa_', see examples at #Ill examples of ShareGPT4V.
    - Contains images from
        - coco train2017
        - llava pretrain
        - sam pretrain dataset 000000-000051
        - share_textvqa
        - web-celebrity
        - web-landmark
        - wikiart
- https://huggingface.co/datasets/X2FD/LVIS-Instruct4V, lvis_instruct4v_220k.json
    - Pure golden diverse instructions by prompting GPT4V.
    - Contains images from
        - coco train2017
        - coco val2017
- https://huggingface.co/datasets/liuhaotian/LLaVA-Instruct-150K/blob/main/llava_v1_5_mix665k.json
    - NOTE: we only used text-only 40688 multi-turn chat examples from it to maintain text-only performance.


## Appendix

### Credits

We extend our thanks to the team behind the datasets, you can find their homepages here:
- ShareGPT4V: https://sharegpt4v.github.io
- LVIS: https://github.com/X2FD/LVIS-INSTRUCT4V
- LLaVA: https://github.com/haotian-liu/LLaVA

### License

Attribution-NonCommercial 4.0 International It should abide by the policy of OpenAI: https://openai.com/policies/terms-of-use

### Ill examples of ShareGPT4V

```py
{'id': 'sa_518556',
 'image': 'sam/images/sa_518556.jpg',
 'conversations': [{'from': 'human',
   'value': "<image>\nWhat's happening in the scene?"},
  {'from': 'gpt',
   'value': "The image captures a charming scene of a two-story brick house nestled on a street corner. The house, with its black roof and chimney, exudes a sense of warmth and homeliness. A red car is parked in front of the house, adding a pop of color to the scene. On the left side of the house, a tree stands tall, providing a touch of nature amidst the urban setting. The sky above is a clear blue, suggesting a bright and sunny day. The perspective of the image is from the street, looking up at the house, giving a sense of scale and grandeur to the structure. The image does not provide any information that can be used to identify the landmark as 'sa_17448'."}]}

{'id': 'sa_164019',
 'image': 'sam/images/sa_164019.jpg',
 'conversations': [{'from': 'human',
   'value': "<image>\nWhat is this photo about'?"},
  {'from': 'gpt',
   'value': 'The image captures a serene scene of a mountain lake. The lake, with its light blue-green hue, is nestled in the heart of a rocky landscape. The rocks, a mix of gray and brown, are scattered around the lake, adding a rugged charm to the scene. The perspective of the image is from above, providing a bird\'s eye view of the lake and its surroundings. The sky, peeking through the top left corner of the image, adds a sense of depth and vastness to the scene. The image does not provide any specific information about the landmark "sa_17448". However, the unique combination of natural elements and the tranquil setting might be recognizable to those familiar with the area.'}]}

...
```